{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('..', 'data_2', 'Keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    doc_annotations = {}\n",
    "    text_lengths = {}\n",
    "\n",
    "    authors_set = set()\n",
    "\n",
    "    for author_folder in os.listdir(DATA_PATH):\n",
    "        authors_set.add(author_folder)\n",
    "        full_path = os.path.join(DATA_PATH, author_folder)\n",
    "        ann_files = list(filter(lambda x: x.endswith('.ann'), os.listdir(full_path)))\n",
    "        for filename in ann_files:\n",
    "            doc_name = os.path.splitext(filename)[0]\n",
    "            if doc_name not in doc_annotations.keys():\n",
    "                doc_annotations[doc_name] = {}\n",
    "\n",
    "            if author_folder in doc_annotations[doc_name].keys():\n",
    "                raise Exception(f'Author \"{author_folder}\" has duplicated annotation for document \"{doc_name}\"')\n",
    "\n",
    "            with open(os.path.join(full_path, filename), 'r') as file_handler:\n",
    "                doc_annotations[doc_name][author_folder] = file_handler.read()\n",
    "\n",
    "            if doc_name not in text_lengths.keys():\n",
    "                with open(os.path.join(full_path, f'{doc_name}.txt'), 'r') as txt_file_handler:\n",
    "                    text_lengths[doc_name] = len(txt_file_handler.read())\n",
    "\n",
    "    return doc_annotations, text_lengths, authors_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_annotations, text_lengths, authors_set = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_annotations = {\n",
    "    k: v for k, v in doc_annotations.items()\n",
    "    if len(v.keys()) > 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_annotations(annotations_str: str, text_length: int):\n",
    "#     result = ['O' for _ in range(text_length)]\n",
    "#     # entities_positions = {}\n",
    "\n",
    "#     annotations = annotations_str.split('\\n')\n",
    "#     for annotation in annotations:\n",
    "#         annotation_parts = annotation.split('\\t')\n",
    "#         if not re.search('([T]{1}[0-9]+)', annotation_parts[0]): continue\n",
    "\n",
    "#         if len(annotation_parts) < 2: print(annotation_parts)\n",
    "#         split_annotation = annotation_parts[1].split(' ')\n",
    "#         label = split_annotation[0]\n",
    "#         current_annotations_parts = ' '.join(split_annotation[1:]).split(';')\n",
    "#         for current_annotations_part in current_annotations_parts:\n",
    "#             current_annotations = current_annotations_part.split(' ')\n",
    "#             if len(current_annotations) > 3: print(current_annotations)\n",
    "\n",
    "#             start_pos, end_pos = current_annotations\n",
    "#             for i in range(int(start_pos), int(end_pos)):\n",
    "#                 result[i] = label\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotation:\n",
    "    def __init__(self, key: str, entity: str, start_pos: int, end_pos: int):\n",
    "        self.key = key\n",
    "        self.entity = entity\n",
    "        self.start_pos = start_pos\n",
    "        self.end_pos = end_pos\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'<{self.key}-{self.entity}-[{self.start_pos}:{self.end_pos}]>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentAnnotation:\n",
    "    def __init__(self, doc_key: str, annotations_str: str, text_length: int):\n",
    "        self.doc_key = doc_key\n",
    "        self.text_length = text_length\n",
    "\n",
    "        self.annotations = self._parse_annotations(annotations_str, text_length)\n",
    "\n",
    "    def _parse_annotations(self, annotations_str: str, text_length: int):\n",
    "        result = []\n",
    "        annotations = annotations_str.split('\\n')\n",
    "        for annotation in annotations:\n",
    "            annotation_parts = annotation.split('\\t')\n",
    "            if not re.search('([T]{1}[0-9]+)', annotation_parts[0]): continue\n",
    "            if len(annotation_parts) < 2: print(annotation_parts)\n",
    "\n",
    "            split_annotation = annotation_parts[1].split(' ')\n",
    "            label = split_annotation[0]\n",
    "            current_annotations_parts = ' '.join(split_annotation[1:]).split(';')\n",
    "\n",
    "            start = int(current_annotations_parts[0].split(' ')[0])\n",
    "            end = int(current_annotations_parts[-1].split(' ')[-1])\n",
    "\n",
    "            result.append(\n",
    "                Annotation(\n",
    "                    key=annotation_parts[0],\n",
    "                    entity=label,\n",
    "                    start_pos=start,\n",
    "                    end_pos=end))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotations(valid_annotations, text_lengths):\n",
    "    parsed_annotations = {\n",
    "        doc_key: {\n",
    "            author: DocumentAnnotation(doc_key, annotations, text_lengths[doc_key])\n",
    "            for author, annotations in annotations_per_author.items()\n",
    "        }\n",
    "        for doc_key, annotations_per_author in valid_annotations.items()\n",
    "    }\n",
    "\n",
    "    return parsed_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_annotations = parse_annotations(valid_annotations, text_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<T1-Person-[286:294]>'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(parsed_annotations['NL-HaNA_1.04.02_6857_0037']['Bert'].annotations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotations_overlap(annotation1: Annotation, annotation2: Annotation, offset_chars: int) -> bool:\n",
    "    # if the two annotations do not even overlap with one character, we return false\n",
    "    if (annotation1.start_pos > annotation2.end_pos or\n",
    "        annotation1.end_pos < annotation2.start_pos):\n",
    "        return False\n",
    "  \n",
    "    out_of_boundary_chars = abs(annotation1.start_pos - annotation2.start_pos) + abs(annotation1.end_pos - annotation2.end_pos)\n",
    "\n",
    "    result = out_of_boundary_chars <= offset_chars\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entity_overlap(doc_annotation1: DocumentAnnotation, doc_annotation2: DocumentAnnotation, offset_chars: int):\n",
    "    assert (doc_annotation1.doc_key == doc_annotation2.doc_key)\n",
    "\n",
    "    mapped_annotations = {}\n",
    "    used_counter_annotations = set()\n",
    "    empty_positions = [1 for _ in range(0, doc_annotation1.text_length)]\n",
    "    for annotation in doc_annotation1.annotations:\n",
    "        for i in range(annotation.start_pos, annotation.end_pos):\n",
    "            empty_positions[i] = 0\n",
    "\n",
    "        mapped_annotations[annotation] = None\n",
    "        for annotation2 in doc_annotation2.annotations:\n",
    "\n",
    "            if annotation2.start_pos > annotation.end_pos:\n",
    "                break\n",
    "\n",
    "            if annotation.start_pos > annotation2.end_pos:\n",
    "                continue\n",
    "\n",
    "            if annotation2.key in used_counter_annotations:\n",
    "                continue\n",
    "\n",
    "            if annotations_overlap(annotation, annotation2, offset_chars):\n",
    "                used_counter_annotations.add(annotation2.key)\n",
    "                mapped_annotations[annotation] = annotation2\n",
    "                break\n",
    "\n",
    "\n",
    "    annotation_maps = [ x.entity for x in mapped_annotations.keys() ]\n",
    "    counter_annotations = [ x.entity if x is not None else 'O' for x in mapped_annotations.values() ]\n",
    "\n",
    "    for annotation2 in doc_annotation2.annotations:\n",
    "        for i in range(annotation2.start_pos, annotation2.end_pos):\n",
    "            empty_positions[i] = 0\n",
    "\n",
    "        if annotation2.key in used_counter_annotations:\n",
    "            continue\n",
    "\n",
    "        for annotation in doc_annotation1.annotations:\n",
    "            if ((annotation2.start_pos > annotation.start_pos and annotation2.start_pos < annotation.end_pos) or\n",
    "                (annotation2.end_pos > annotation.start_pos and annotation2.end_pos < annotation.end_pos)):\n",
    "\n",
    "                annotation_maps.append('O')\n",
    "                counter_annotations.append(annotation2.entity)\n",
    "                break\n",
    "\n",
    "    free_positions = sum(empty_positions)\n",
    "    for _ in range(free_positions):\n",
    "        annotation_maps.append('O')\n",
    "        counter_annotations.append('O')\n",
    "\n",
    "    if annotation_maps == counter_annotations:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = cohen_kappa_score(annotation_maps, counter_annotations, weights='quadratic')\n",
    "\n",
    "    # if result < 0:\n",
    "    #     print(result)\n",
    "    #     print(len(annotation_maps))\n",
    "    #     print(annotation_maps)\n",
    "    #     print(len(counter_annotations))\n",
    "    #     print(counter_annotations)\n",
    "    #     raise Exception('test')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_matrix(parsed_annotations, offset_chars: int, authors_set: set):\n",
    "    comparisons = {\n",
    "        author_1 : {\n",
    "            author_2: []\n",
    "            for author_2 in authors_set\n",
    "        } for author_1 in authors_set\n",
    "    }\n",
    "\n",
    "    for _, annotations in parsed_annotations.items():\n",
    "        for author_1, author_2 in itertools.product(authors_set, authors_set):\n",
    "            kappa_score = 0\n",
    "\n",
    "            if author_1 != author_2 and author_1 in annotations.keys() and author_2 in annotations.keys():\n",
    "                kappa_score = calculate_entity_overlap(annotations[author_1], annotations[author_2], offset_chars)\n",
    "\n",
    "            comparisons[author_1][author_2].append(kappa_score)\n",
    "\n",
    "    return comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparisons = {\n",
    "#     author_1 : {\n",
    "#         author_2: []\n",
    "#         for author_2 in authors_set\n",
    "#     } for author_1 in authors_set\n",
    "# }\n",
    "\n",
    "# for doc_key, annotations_per_author in valid_annotations.items():\n",
    "#     processed_annotations_per_author = {}\n",
    "#     for author, annotations in annotations_per_author.items():\n",
    "#         processed_annotations_per_author[author] = parse_annotations(annotations, text_lengths[doc_key])\n",
    "#         if author not in comparisons.keys():\n",
    "#             comparisons[author] = {}\n",
    "\n",
    "    # for author_1, author_2 in itertools.product(authors_set, authors_set):\n",
    "    #     if author_1 == author_2:\n",
    "    #         kappa = 0\n",
    "    #     else:\n",
    "    #         kappa = cohen_kappa_score(\n",
    "    #             processed_annotations_per_author[author_1],\n",
    "    #             processed_annotations_per_author[author_2])\n",
    "\n",
    "    #     comparisons[author_1][author_2].append(kappa)\n",
    "    #     comparisons[author_2][author_1].append(kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comparison_matrix(comparisons):\n",
    "    names = list(comparisons.keys())\n",
    "    print('\\t', end='')\n",
    "    print('\\t'.join(names))\n",
    "    for author_1 in names:\n",
    "        print(author_1, end='\\t')\n",
    "        for author_2 in names:\n",
    "            print(round(np.mean(comparisons[author_1][author_2]), 2), end='\\t')\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparison(parsed_annotations, authors_set, offset_chars: int):\n",
    "    comparison_matrix = create_comparison_matrix(parsed_annotations, offset_chars, authors_set)\n",
    "    print_comparison_matrix(comparison_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSilja\tEmma\tYolien\tJonas\tRoos\tBert\n",
      "Silja\t0.0\t0.13\t0.09\t0.12\t0.15\t0.04\t\n",
      "Emma\t0.11\t0.0\t0.07\t0.1\t0.12\t0.02\t\n",
      "Yolien\t0.1\t0.08\t0.0\t0.06\t0.13\t0.04\t\n",
      "Jonas\t0.1\t0.12\t0.05\t0.0\t0.12\t0.04\t\n",
      "Roos\t0.17\t0.12\t0.12\t0.11\t0.0\t0.03\t\n",
      "Bert\t0.03\t0.02\t0.05\t0.03\t0.04\t0.0\t\n"
     ]
    }
   ],
   "source": [
    "run_comparison(parsed_annotations, authors_set, offset_chars=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSilja\tEmma\tYolien\tJonas\tRoos\tBert\n",
      "Silja\t0.0\t0.16\t0.13\t0.15\t0.18\t0.05\t\n",
      "Emma\t0.15\t0.0\t0.1\t0.13\t0.15\t0.03\t\n",
      "Yolien\t0.12\t0.11\t0.0\t0.07\t0.16\t0.05\t\n",
      "Jonas\t0.13\t0.15\t0.07\t0.0\t0.14\t0.05\t\n",
      "Roos\t0.21\t0.15\t0.16\t0.13\t0.0\t0.05\t\n",
      "Bert\t0.04\t0.03\t0.07\t0.05\t0.05\t0.0\t\n"
     ]
    }
   ],
   "source": [
    "run_comparison(parsed_annotations, authors_set, offset_chars=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b75f3199d40dc5b32c50d7e73d50b0653ef4e42fc29a92d9ddb9ff9d4b03964"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ocr': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
