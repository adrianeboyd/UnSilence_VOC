{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('..', 'data_2', 'Keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    doc_annotations = {}\n",
    "    text_lengths = {}\n",
    "\n",
    "    authors_set = set()\n",
    "\n",
    "    for author_folder in os.listdir(DATA_PATH):\n",
    "        authors_set.add(author_folder)\n",
    "        full_path = os.path.join(DATA_PATH, author_folder)\n",
    "        ann_files = list(filter(lambda x: x.endswith('.ann'), os.listdir(full_path)))\n",
    "        for filename in ann_files:\n",
    "            doc_name = os.path.splitext(filename)[0]\n",
    "            if doc_name not in doc_annotations.keys():\n",
    "                doc_annotations[doc_name] = {}\n",
    "\n",
    "            if author_folder in doc_annotations[doc_name].keys():\n",
    "                raise Exception(f'Author \"{author_folder}\" has duplicated annotation for document \"{doc_name}\"')\n",
    "\n",
    "            with open(os.path.join(full_path, filename), 'r') as file_handler:\n",
    "                doc_annotations[doc_name][author_folder] = file_handler.read()\n",
    "\n",
    "            if doc_name not in text_lengths.keys():\n",
    "                with open(os.path.join(full_path, f'{doc_name}.txt'), 'r') as txt_file_handler:\n",
    "                    text_lengths[doc_name] = len(txt_file_handler.read())\n",
    "\n",
    "    return doc_annotations, text_lengths, authors_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_annotations, text_lengths, authors_set = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for a, b in doc_annotations.items():\n",
    "#     if len(b.keys()) > 1 and 'Bert' not in b.keys():\n",
    "#         i += 1\n",
    "#         if i > 1:\n",
    "#             print(a)\n",
    "#             break\n",
    "\n",
    "# key = 'NL-HaNA_1.04.02_6863_0208'\n",
    "# doc_annotations = {\n",
    "#     k: v for k, v in doc_annotations.items() if k == key\n",
    "# }\n",
    "\n",
    "# print(doc_annotations[key].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n'.join([x for x in doc_annotations[key]['Bert'].split('\\n') if x.startswith('T')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n'.join([x for x in doc_annotations[key]['Roos'].split('\\n') if x.startswith('T')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_annotations = {\n",
    "    k: v for k, v in doc_annotations.items()\n",
    "    if len(v.keys()) > 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_annotations(annotations_str: str, text_length: int):\n",
    "#     result = ['O' for _ in range(text_length)]\n",
    "#     # entities_positions = {}\n",
    "\n",
    "#     annotations = annotations_str.split('\\n')\n",
    "#     for annotation in annotations:\n",
    "#         annotation_parts = annotation.split('\\t')\n",
    "#         if not re.search('([T]{1}[0-9]+)', annotation_parts[0]): continue\n",
    "\n",
    "#         if len(annotation_parts) < 2: print(annotation_parts)\n",
    "#         split_annotation = annotation_parts[1].split(' ')\n",
    "#         label = split_annotation[0]\n",
    "#         current_annotations_parts = ' '.join(split_annotation[1:]).split(';')\n",
    "#         for current_annotations_part in current_annotations_parts:\n",
    "#             current_annotations = current_annotations_part.split(' ')\n",
    "#             if len(current_annotations) > 3: print(current_annotations)\n",
    "\n",
    "#             start_pos, end_pos = current_annotations\n",
    "#             for i in range(int(start_pos), int(end_pos)):\n",
    "#                 result[i] = label\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotation:\n",
    "    def __init__(self, key: str, entity: str, start_pos: int, end_pos: int):\n",
    "        self.key = key\n",
    "        self.entity = entity\n",
    "        self.start_pos = start_pos\n",
    "        self.end_pos = end_pos\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'<{self.key}-{self.entity}-[{self.start_pos}:{self.end_pos}]>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_labels = ['DuplicatePage', 'TranscriptionError_Document']\n",
    "\n",
    "class DocumentAnnotation:\n",
    "    def __init__(self, doc_key: str, annotations_str: str, text_length: int):\n",
    "        self.doc_key = doc_key\n",
    "        self.text_length = text_length\n",
    "        self.is_valid=True\n",
    "\n",
    "        self.annotations = self._parse_annotations(annotations_str)\n",
    "\n",
    "    def _parse_annotations(self, annotations_str: str):\n",
    "        result = []\n",
    "        annotations = annotations_str.split('\\n')\n",
    "        for annotation in annotations:\n",
    "            annotation_parts = annotation.split('\\t')\n",
    "            if not re.search('([T]{1}[0-9]+)', annotation_parts[0]): continue\n",
    "            if len(annotation_parts) < 2: print(annotation_parts)\n",
    "\n",
    "            split_annotation = annotation_parts[1].split(' ')\n",
    "            label = split_annotation[0]\n",
    "\n",
    "            if label in invalid_labels:\n",
    "                self.is_valid=False\n",
    "                continue\n",
    "\n",
    "            current_annotations_parts = ' '.join(split_annotation[1:]).split(';')\n",
    "\n",
    "            start = int(current_annotations_parts[0].split(' ')[0])\n",
    "            end = int(current_annotations_parts[-1].split(' ')[-1])\n",
    "\n",
    "            result.append(\n",
    "                Annotation(\n",
    "                    key=annotation_parts[0],\n",
    "                    entity=label,\n",
    "                    start_pos=start,\n",
    "                    end_pos=end))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotations(valid_annotations, text_lengths):\n",
    "    parsed_annotations = {\n",
    "        doc_key: {\n",
    "            author: DocumentAnnotation(doc_key, annotations, text_lengths[doc_key])\n",
    "            for author, annotations in annotations_per_author.items()\n",
    "        }\n",
    "        for doc_key, annotations_per_author in valid_annotations.items()\n",
    "    }\n",
    "\n",
    "    # Remove invalid annotations\n",
    "    parsed_annotations = {\n",
    "        doc_key: {\n",
    "            author: doc_annotation\n",
    "            for author, doc_annotation in annotations_per_author.items()\n",
    "            if doc_annotation.is_valid\n",
    "        }\n",
    "        for doc_key, annotations_per_author in parsed_annotations.items()\n",
    "    }\n",
    "\n",
    "    # Remove documents where we are left with only one annotation\n",
    "    parsed_annotations = {\n",
    "        doc_key: annotations_per_author\n",
    "        for doc_key, annotations_per_author in parsed_annotations.items()\n",
    "        if len(annotations_per_author.keys()) > 1\n",
    "    }\n",
    "\n",
    "    return parsed_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_annotations = parse_annotations(valid_annotations, text_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotations_overlap(annotation1: Annotation, annotation2: Annotation, offset_chars: int, match_entity: bool) -> bool:\n",
    "    # if the two annotations do not even overlap with one character, we return false\n",
    "    if (annotation1.start_pos > annotation2.end_pos or\n",
    "        annotation1.end_pos < annotation2.start_pos):\n",
    "        return False\n",
    "\n",
    "    if match_entity and (annotation1.entity != annotation2.entity):\n",
    "        return False\n",
    "\n",
    "    out_of_boundary_chars = abs(annotation1.start_pos - annotation2.start_pos) + abs(annotation1.end_pos - annotation2.end_pos)\n",
    "\n",
    "    result = out_of_boundary_chars <= offset_chars\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mapped_annotations(mapped_annotations: dict):\n",
    "    for ann1, ann2 in mapped_annotations.items():\n",
    "        print(f'{ann1.key} <{ann1.start_pos}-{ann1.end_pos}>  ---', end='')\n",
    "        if ann2 is None:\n",
    "            print('NONE')\n",
    "        else:\n",
    "            print(f'{ann2.key} <{ann2.start_pos}-{ann2.end_pos}>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapping_annotation(annotation_to_compare: Annotation, annotations: List[Annotation], keys_to_skip: List[str], offset_chars: int, match_entity: bool) -> Annotation:\n",
    "    overlaps = []\n",
    "    for annotation2 in annotations:\n",
    "\n",
    "        if annotation_to_compare.start_pos > annotation2.end_pos:\n",
    "            continue\n",
    "\n",
    "        if annotation2.key in keys_to_skip:\n",
    "            continue\n",
    "\n",
    "        if annotations_overlap(annotation_to_compare, annotation2, offset_chars, match_entity):\n",
    "            overlaps.append(annotation2)\n",
    "\n",
    "    if len(overlaps) == 0:\n",
    "        return None\n",
    "\n",
    "    for overlap in overlaps:\n",
    "        if overlap.entity == annotation_to_compare.entity:\n",
    "            return overlap\n",
    "\n",
    "    return overlaps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entity_overlap(doc_annotation1: DocumentAnnotation, doc_annotation2: DocumentAnnotation, offset_chars: int, debug: bool = False):\n",
    "    assert (doc_annotation1.doc_key == doc_annotation2.doc_key)\n",
    "\n",
    "    mapped_annotations = {}\n",
    "    used_counter_annotations = set()\n",
    "    empty_positions = [1 for _ in range(0, doc_annotation1.text_length)]\n",
    "    for annotation in doc_annotation1.annotations:\n",
    "        for i in range(annotation.start_pos, annotation.end_pos):\n",
    "            empty_positions[i] = 0\n",
    "\n",
    "    # Perform iteration using strict overlap matching\n",
    "    for annotation in doc_annotation1.annotations:\n",
    "        overlapping_annotation = get_overlapping_annotation(annotation, doc_annotation2.annotations, used_counter_annotations, offset_chars, match_entity=True)\n",
    "        if overlapping_annotation is not None:\n",
    "            used_counter_annotations.add(overlapping_annotation.key)\n",
    "            mapped_annotations[annotation] = overlapping_annotation\n",
    "\n",
    "    # Perform iteration using loose overlap matching\n",
    "    for annotation in doc_annotation1.annotations:\n",
    "        if annotation in mapped_annotations.keys():\n",
    "            continue\n",
    "\n",
    "        overlapping_annotation = get_overlapping_annotation(annotation, doc_annotation2.annotations, used_counter_annotations, offset_chars, match_entity=False)\n",
    "        if overlapping_annotation is not None:\n",
    "            used_counter_annotations.add(overlapping_annotation.key)\n",
    "\n",
    "        mapped_annotations[annotation] = overlapping_annotation\n",
    "\n",
    "    if debug:\n",
    "        print_mapped_annotations(mapped_annotations)\n",
    "    annotation_maps = [ x.entity for x in mapped_annotations.keys() ]\n",
    "    counter_annotations = [ x.entity if x is not None else 'O' for x in mapped_annotations.values() ]\n",
    "\n",
    "    for annotation2 in doc_annotation2.annotations:\n",
    "        for i in range(annotation2.start_pos, annotation2.end_pos):\n",
    "            empty_positions[i] = 0\n",
    "\n",
    "        if annotation2.key in used_counter_annotations:\n",
    "            continue\n",
    "\n",
    "        # for annotation in doc_annotation1.annotations:\n",
    "        #     if ((annotation2.start_pos > annotation.start_pos and annotation2.start_pos < annotation.end_pos) or\n",
    "        #         (annotation2.end_pos > annotation.start_pos and annotation2.end_pos < annotation.end_pos)):\n",
    "\n",
    "        annotation_maps.append('O')\n",
    "        counter_annotations.append(annotation2.entity)\n",
    "        #         break\n",
    "\n",
    "    free_positions = sum(empty_positions)\n",
    "    for _ in range(free_positions):\n",
    "        annotation_maps.append('O')\n",
    "        counter_annotations.append('O')\n",
    "\n",
    "    if annotation_maps == counter_annotations:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = cohen_kappa_score(annotation_maps, counter_annotations)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_matrix(parsed_annotations, offset_chars: int, authors_set: set):\n",
    "    comparisons = {\n",
    "        author_1 : {\n",
    "            author_2: []\n",
    "            for author_2 in authors_set\n",
    "        } for author_1 in authors_set\n",
    "    }\n",
    "\n",
    "    for _, annotations in parsed_annotations.items():\n",
    "        for author_1, author_2 in itertools.product(authors_set, authors_set):\n",
    "            kappa_score = 0\n",
    "\n",
    "            if author_1 != author_2 and author_1 in annotations.keys() and author_2 in annotations.keys():\n",
    "                debug=False#(author_2=='Roos' and author_1=='Bert')\n",
    "                kappa_score = calculate_entity_overlap(annotations[author_1], annotations[author_2], offset_chars, debug=debug)\n",
    "                # if debug:\n",
    "                #     for a in annotations[author_1].annotations:\n",
    "                #         print(a)\n",
    "                # if kappa_score < 0.2:\n",
    "                #     print(annotations[author_1].doc_key)\n",
    "                #     print(author_1)\n",
    "                #     print(author_2)\n",
    "                #     raise Exception('test')\n",
    "                # print(f'<{author_1}, {author_2}, {kappa_score}>')\n",
    "\n",
    "            comparisons[author_1][author_2].append(kappa_score)\n",
    "\n",
    "    return comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparisons = {\n",
    "#     author_1 : {\n",
    "#         author_2: []\n",
    "#         for author_2 in authors_set\n",
    "#     } for author_1 in authors_set\n",
    "# }\n",
    "\n",
    "# for doc_key, annotations_per_author in valid_annotations.items():\n",
    "#     processed_annotations_per_author = {}\n",
    "#     for author, annotations in annotations_per_author.items():\n",
    "#         processed_annotations_per_author[author] = parse_annotations(annotations, text_lengths[doc_key])\n",
    "#         if author not in comparisons.keys():\n",
    "#             comparisons[author] = {}\n",
    "\n",
    "    # for author_1, author_2 in itertools.product(authors_set, authors_set):\n",
    "    #     if author_1 == author_2:\n",
    "    #         kappa = 0\n",
    "    #     else:\n",
    "    #         kappa = cohen_kappa_score(\n",
    "    #             processed_annotations_per_author[author_1],\n",
    "    #             processed_annotations_per_author[author_2])\n",
    "\n",
    "    #     comparisons[author_1][author_2].append(kappa)\n",
    "    #     comparisons[author_2][author_1].append(kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comparison_matrix(comparisons):\n",
    "    names = list(comparisons.keys())\n",
    "    print('\\t', end='')\n",
    "    print('\\t'.join(names))\n",
    "    for author_1 in names:\n",
    "        print(author_1, end='\\t')\n",
    "        for author_2 in names:\n",
    "            print(round(np.mean(comparisons[author_1][author_2]), 2), end='\\t')\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparison(parsed_annotations, authors_set, offset_chars: int):\n",
    "    comparison_matrix = create_comparison_matrix(parsed_annotations, offset_chars, authors_set)\n",
    "    print_comparison_matrix(comparison_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRoos\tEmma\tSilja\tBert\tJonas\tYolien\n",
      "Roos\t0.0\t0.15\t0.15\t0.02\t0.1\t0.08\t\n",
      "Emma\t0.15\t0.0\t0.1\t0.03\t0.12\t0.05\t\n",
      "Silja\t0.15\t0.1\t0.0\t0.01\t0.06\t0.08\t\n",
      "Bert\t0.02\t0.03\t0.01\t0.0\t0.03\t0.02\t\n",
      "Jonas\t0.1\t0.12\t0.06\t0.03\t0.0\t0.04\t\n",
      "Yolien\t0.08\t0.05\t0.08\t0.02\t0.04\t0.0\t\n"
     ]
    }
   ],
   "source": [
    "run_comparison(parsed_annotations, authors_set, offset_chars=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRoos\tEmma\tSilja\tBert\tJonas\tYolien\n",
      "Roos\t0.0\t0.19\t0.2\t0.02\t0.13\t0.13\t\n",
      "Emma\t0.19\t0.0\t0.18\t0.05\t0.19\t0.09\t\n",
      "Silja\t0.2\t0.18\t0.0\t0.02\t0.09\t0.13\t\n",
      "Bert\t0.02\t0.05\t0.02\t0.0\t0.05\t0.03\t\n",
      "Jonas\t0.13\t0.19\t0.09\t0.05\t0.0\t0.06\t\n",
      "Yolien\t0.13\t0.09\t0.13\t0.03\t0.06\t0.0\t\n"
     ]
    }
   ],
   "source": [
    "run_comparison(parsed_annotations, authors_set, offset_chars=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRoos\tEmma\tSilja\tBert\tJonas\tYolien\n",
      "Roos\t0.0\t0.19\t0.2\t0.02\t0.13\t0.13\t\n",
      "Emma\t0.19\t0.0\t0.18\t0.05\t0.19\t0.09\t\n",
      "Silja\t0.2\t0.18\t0.0\t0.02\t0.09\t0.13\t\n",
      "Bert\t0.02\t0.05\t0.02\t0.0\t0.05\t0.03\t\n",
      "Jonas\t0.13\t0.19\t0.09\t0.05\t0.0\t0.07\t\n",
      "Yolien\t0.13\t0.09\t0.13\t0.03\t0.07\t0.0\t\n"
     ]
    }
   ],
   "source": [
    "run_comparison(parsed_annotations, authors_set, offset_chars=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b75f3199d40dc5b32c50d7e73d50b0653ef4e42fc29a92d9ddb9ff9d4b03964"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ocr': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
